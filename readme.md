Keywords: game play, human ai collaboration, theory of mind





### Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind Aware GPT-4

**Link:** [Hugging Face - Suspicion-Agent-Demo](https://huggingface.co/spaces/cr7-gjx/Suspicion-Agent-Demo)

**Research Problem:** 
How to leverage GPT-4's Theory of Mind capabilities to enhance its performance in playing games with imperfect information.

**Motivation:** 
Games involving imperfect information, such as Werewolf, require understanding and predicting the intentions and beliefs of other players, which aligns with the Theory of Mind abilities being developed in advanced language models.

**Contribution:** 
This work introduces the "Suspicion-Agent" model that applies Theory of Mind concepts to improve decision-making in imperfect information games by using GPT-4, demonstrating enhanced strategic play and better alignment with human cognitive processes in such scenarios.

### HI-TOM : A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models

**Research Problem:** 
How to evaluate the capability of large language models to reason about higher-order Theory of Mind (ToM) scenarios.

**Motivation:** 
Understanding and predicting not just direct beliefs but also nested beliefs (e.g., "I think you think that I think") is crucial for sophisticated human-like reasoning, which is a growing focus in the development of large language models.

**Contribution:** 
HI-TOM provides a comprehensive benchmark that assesses the ability of language models to engage in higher-order Theory of Mind reasoning, offering a structured approach to measure and improve LLMs' capabilities in complex cognitive tasks.

These summaries provide a concise overview of the focus, motivation, and contributions of the papers, helping to understand their significance in the field of AI and cognitive science.





### SmartPlay: A Benchmark for LLMs as Intelligent Agents

**Research Problem:** 
How to effectively benchmark large language models (LLMs) as intelligent agents across various capabilities using interactive games.

**Motivation:** 
Existing benchmarks often fail to comprehensively evaluate the diverse skills required for LLMs to function as autonomous agents in dynamic and interactive environments.

**Contribution:** 
SmartPlay introduces a suite of games, including Rock-Paper-Scissors and Tower of Hanoi, each designed to test specific LLM capabilities like planning, multi-hop reasoning, and spatial understanding, providing a robust framework for assessing LLMs' performance in real-world tasks.









### Human-Agent Cooperation in Games under Incomplete Information through Natural Language Communication

**Research Problem:** 
How to enable effective human-agent cooperation in strategic games with incomplete information through natural language communication.

**Motivation:** 
Effective cooperation in games with incomplete information is challenging, especially when communication is limited to natural language, requiring innovative strategies to bridge the information gap between human and agent players.

**Contribution:** 
The paper introduces a shared-control game model and a novel algorithm called Asymmetric Information-Set Monte Carlo Tree Search with Flag exchange (AISMCTS-F). This approach uses natural language communication translated into a finite set of flags to enhance coordination and decision-making in cooperative settings.



### Sharing the Cost of Success: A Game for Evaluating and Learning Collaborative Multi-Agent Instruction Giving and Following Policies

**Research Problem:** 
How to design and evaluate multi-agent systems that can effectively share tasks and the associated costs in achieving collaborative goals.

**Motivation:** 
In multi-agent systems, achieving effective collaboration often requires balancing the distribution of task costs and rewards among agents, which is a critical aspect of designing cooperative policies.

**Contribution:** 
This research introduces a game-based framework that simulates scenarios where agents must collaborate to achieve common goals while equitably sharing the costs of their actions. The framework assesses and trains agents in instruction giving and following, fostering improved multi-agent collaboration.

These summaries provide an overview of each paperâ€™s core research question, motivation, and contributions, reflecting the latest advancements in leveraging AI for interactive and cooperative tasks.





### Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain

**Research Problem:** 
How to model and optimize collaborative AI agents to improve human experiences, rather than merely maximizing task performance.

**Motivation:** 
Current AI systems in human-agent collaborations often prioritize task success, which can lead to suboptimal or even detrimental experiences for human partners.

**Contribution:** 
The paper proposes a novel "human-centered" modeling scheme and introduces the Reinforcement Learning from Human Gain approach, which focuses on enhancing human goal achievement while maintaining agents' capabilities.



### CLEMBench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents

**Research Problem:** 
How to effectively benchmark and evaluate the conversational capabilities of language models optimized for chat in a dynamic, interactive environment.

**Motivation:** 
Existing benchmarks often lack the interactive and adaptive nature of real-world conversations, limiting the assessment of language models' performance in practical scenarios.

**Contribution:** 
CLEMBench provides a novel evaluation framework using gameplay to simulate real-time interactions, offering a comprehensive assessment of conversational agents' responsiveness and adaptability in various game contexts.



### MINDAGENT: Emergent Gaming Interaction

**Research Problem:** 
How to leverage emergent interactions in gaming to develop more sophisticated and adaptable AI agents.

**Motivation:** 
Emergent interactions, where complex behavior arises from simple rules, are crucial in creating engaging and realistic AI in games, yet they are underutilized in current AI development.

**Contribution:** 
MINDAGENT explores emergent interactions as a foundation for building AI agents that can adapt and evolve in unpredictable gaming environments, enhancing the overall gaming experience and AI development process.



### LLM-Powered Hierarchical Language Agent for Real-time Human-AI Coordination

**Research Problem:** 
How to design hierarchical language agents that can effectively coordinate with humans in real-time for complex task management.

**Motivation:** 
The challenge of real-time coordination in dynamic tasks often leads to inefficiencies and failures in human-AI collaborations.

**Contribution:** 
The paper presents a hierarchical framework that uses large language models (LLMs) to enable better task delegation and communication in real-time scenarios, improving overall coordination and efficiency in human-AI interactions.















